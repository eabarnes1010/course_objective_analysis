{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDJ9DAl4It7X"
   },
   "source": [
    "# A basic example of a full neural network\n",
    "[![Latest release](https://badgen.net/github/release/Naereen/Strapdown.js)](https://github.com/eabarnes1010/course_objective_analysis/tree/main/code)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eabarnes1010/course_objective_analysis/blob/main/code/ann_basics.ipynb)\n",
    "\n",
    "Below is a simple example of how to code a neural network using keras tensor flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6963,
     "status": "ok",
     "timestamp": 1645363379244,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "-ErKAKhhIt7Y"
   },
   "outputs": [],
   "source": [
    "# Import tensorflow and keras\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats, odr\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['figure.figsize'] = (12.0/2.5, 8.0/2.5)\n",
    "\n",
    "# this is for running in colaboratory\n",
    "# show plots inline\n",
    "#%matplotlib inline    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645363379244,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "pBYfPWXZS-lG",
    "outputId": "90309bd6-9da1-4609-8c7c-aedbccae5112"
   },
   "outputs": [],
   "source": [
    "# random numbers\n",
    "get_ipython().run_line_magic('env', 'PYTHONHASHSEED=99')\n",
    "# %env PYTHONHASHSEED=99\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh--vBbKBilU"
   },
   "source": [
    "## Linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 308,
     "status": "ok",
     "timestamp": 1645363379545,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "An-REbxGBilX"
   },
   "outputs": [],
   "source": [
    "url = 'https://github.com/chasinginfinity/ml-from-scratch/raw/master/02%20Linear%20Regression%20using%20Gradient%20Descent/data.csv'\n",
    "data = pd.read_csv(url)\n",
    "x = np.array(data.iloc[:, 0])\n",
    "y = np.array(data.iloc[:, 1])\n",
    "x = (x-np.mean(x))/np.std(x)\n",
    "y = (y-np.mean(y))/np.std(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "executionInfo": {
     "elapsed": 469,
     "status": "ok",
     "timestamp": 1645363380008,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "_DfFFMGDBilZ",
    "outputId": "528b54ec-c867-466e-e2e3-cdb7064a7ce4"
   },
   "outputs": [],
   "source": [
    "x = np.expand_dims(x, axis=1)\n",
    "y = np.expand_dims(y, axis=1)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('X value')\n",
    "plt.ylabel('Y value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14685,
     "status": "ok",
     "timestamp": 1645363394688,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "xf4LPJpmBilf",
    "outputId": "b118c116-79bc-4f99-9e0a-8a04c7385896"
   },
   "outputs": [],
   "source": [
    "# Example: build a simple, fully-connected network \n",
    "# (aka multi-layer perceptron).\n",
    "# Nodes of each layer are connected to all nodes of the next layer.\n",
    "\n",
    "# In Tensorflow/Keras a NN model is built in layers. \n",
    "# Most common type is sequential layers - one layer after the other with \n",
    "# connections only between neighboring layers.\n",
    "\n",
    "# define the model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(0.01),  # Adam optimizer\n",
    "            loss='mse',                               # mean squared error\n",
    "            metrics=['mae'])                          # mean absolute error\n",
    "\n",
    "# Now train the model\n",
    "# training input: x\n",
    "# training output: y  \n",
    "# Train on batches of 64 samples (chunk size).\n",
    "# Epochs: run through all training data that many times. Order gets shuffled.\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x,y,test_size = .2, shuffle=True, random_state = 12)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=250, batch_size=64, verbose=0, validation_data=(x_val,y_val), shuffle=True)   \n",
    "print('done training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 695,
     "status": "ok",
     "timestamp": 1645363395376,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "VtpGLrTvS-lK",
    "outputId": "d200bcac-02a0-43cb-f4e8-7bd0ead94c4d"
   },
   "outputs": [],
   "source": [
    "#from keras.callbacks import history \n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'],label = 'training')\n",
    "plt.plot(history.history['val_loss'], label = 'validation')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim(0,1.)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['mae'],label = 'training')\n",
    "plt.plot(history.history['val_mae'], label = 'validation')\n",
    "plt.title('mean absolute error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.ylim(0,1.)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "executionInfo": {
     "elapsed": 481,
     "status": "ok",
     "timestamp": 1645363395851,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "ORJXd1lqBilh",
    "outputId": "d3506108-09f6-424d-f589-ce78e5d82a7d"
   },
   "outputs": [],
   "source": [
    "# output predictions based on input x\n",
    "ypred = model.predict(x)\n",
    "\n",
    "# plot predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, y, '.', color='black', label='truth')\n",
    "plt.plot(x, ypred, 'x', color='red', label='ANN prediction')\n",
    "\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(np.squeeze(x),np.squeeze(y))\n",
    "plt.plot(x,intercept+x*slope,'-',color = 'black', label = 'LSQ: x vs y')\n",
    "plt.legend()\n",
    "\n",
    "#plt.ylim(0,120)\n",
    "#plt.xlim(0,120)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntge4kd1Bilm"
   },
   "source": [
    "# A non-linear, more interesting example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1645363395851,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "JNx0YMrhBiln"
   },
   "outputs": [],
   "source": [
    "# MODIFY: define a function to be estimated\n",
    "def my_function(x):\n",
    "    return np.round(np.sin(1.15*x * np.pi))\n",
    "#     return np.abs(np.sin(x * np.pi/2))                   # MODIFY: uncomment for another interesting function to use\n",
    "    #return np.sin(x * np.pi/2)                            # MODIFY: uncomment for another interesting function to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 518,
     "status": "ok",
     "timestamp": 1645363396363,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "EQk4PAhJIt7a",
    "outputId": "bd4f742f-84d7-4955-d0ce-a7f8202cbd92"
   },
   "outputs": [],
   "source": [
    "# make some \"truth\" data\n",
    "# generate lots of sample pairs (x, f(x))\n",
    "\n",
    "n_samples = 10000\n",
    "x = np.random.random((n_samples,1))\n",
    "y = my_function(x)  \n",
    "\n",
    "# plot the (x,y) pairs.\n",
    "plt.figure()\n",
    "plt.plot(x, y, '.', color='black')\n",
    "plt.title('Actual data we are trying to predict')\n",
    "plt.xlabel('input value')\n",
    "plt.ylabel('output value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H05Tj_07S-lN"
   },
   "source": [
    "Activation Functions: https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "\n",
    "Common choices include:\n",
    "* relu\n",
    "* sigmoid\n",
    "* tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "executionInfo": {
     "elapsed": 26533,
     "status": "ok",
     "timestamp": 1645363422884,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "HAA5YDt9It7h",
    "outputId": "04c3657e-a505-42c0-99db-ad37aa131666"
   },
   "outputs": [],
   "source": [
    "# Example: build a simple, fully-connected network \n",
    "# (aka multi-layer perceptron).\n",
    "# Nodes of each layer are connected to all nodes of the next layer.\n",
    "\n",
    "# In Keras a NN model is built in layers. \n",
    "# Most common type is sequential layers - one layer after the other with \n",
    "# connections only between neighboring layers.\n",
    "\n",
    "n_units = 16                                          # MODIFY: number of units in each layer\n",
    "activation = \"relu\"                                   # MODIFY: activation function, e.g. \"relu\", \"sigmoid\", \"tanh\", \"linear\"\n",
    "n_epochs = 200                                        # MODIFY: run through all training data that many times. Order gets shuffled.\n",
    "learning_rate = 0.01                                  # MODIFY: how much to update weights for each batch\n",
    "batch_size = 128                                      # MODIFY: train on batches (chunks) of samples\n",
    "\n",
    "# define the model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input layer is defined later\n",
    "\n",
    "# First hidden layer: densely-connected layer with \n",
    "# n_units units and activation function 'relu'.\n",
    "model.add(layers.Dense(n_units, activation=activation))  \n",
    "\n",
    "# Second hidden layer:\n",
    "model.add(layers.Dense(n_units, activation=activation)) # MODIFY: comment out if you only want one layer in your network\n",
    "\n",
    "# final layer:  just 1 node and no activation function\n",
    "model.add(layers.Dense(1,activation=None))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),  # Adam optimizer\n",
    "            loss='mae',                                        # mean absolute error = mae\n",
    "            metrics=['mse'])                                   # mean squared error = mse\n",
    "\n",
    "# Now train the model\n",
    "# training input: x\n",
    "# training output: y  \n",
    "history = model.fit(x, y, epochs=n_epochs, batch_size=batch_size, verbose=0, validation_split=0.2, shuffle=True)\n",
    "print('done training')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#-----------------------------------------\n",
    "# plot the loss during training\n",
    "#-----------------------------------------\n",
    "#from keras.callbacks import history \n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'],label = 'training')\n",
    "plt.plot(history.history['val_loss'], label = 'validation')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['mse'],label = 'training')\n",
    "plt.plot(history.history['val_mse'], label = 'validation')\n",
    "plt.title('mean squared error')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1645363423934,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "8u1o4h71It7p",
    "outputId": "6b069aa7-2f8b-4eb5-d623-8314d72f5ede"
   },
   "outputs": [],
   "source": [
    "# make predictions with your model\n",
    "ypred = model.predict(x)\n",
    "# create new samples in x\n",
    "px = np.random.random((100 ,1))\n",
    "# predict y\n",
    "py = model.predict(px)\n",
    "\n",
    "# plot predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, y, '.', color='black', label='truth')\n",
    "plt.plot(x, ypred, 'x', color='gray', label='prediction of training data')\n",
    "plt.plot(px, py, '.', color='red', label='prediction of validation data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ak8pEejxS-lO"
   },
   "source": [
    "# Same example, but now with classification instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1645363423934,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "q_7BtoypS-lO",
    "outputId": "e00f6b0f-549e-4d06-83c2-987bde6a18b4"
   },
   "outputs": [],
   "source": [
    "y_class = np.asarray(np.round(y),dtype='int')\n",
    "num_classes = len(np.unique(y_class))\n",
    "print('classes = ' + str(np.unique(y_class)))\n",
    "\n",
    "n_units = 16                                          # MODIFY: number of units in each layer\n",
    "activation = \"relu\"                                   # MODIFY: activation function, e.g. \"relu\", \"sigmoid\", \"tanh\", \"linear\"\n",
    "n_epochs = 200                                        # MODIFY: run through all training data that many times. Order gets shuffled.\n",
    "learning_rate = 0.01                                  # MODIFY: how much to update weights for each batch\n",
    "batch_size = 128                                      # MODIFY: train on batches (chunks) of samples\n",
    "\n",
    "# define the model\n",
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Input layer is defined later\n",
    "\n",
    "# First hidden layer: densely-connected layer with n_units units and activation function 'relu'.\n",
    "model.add(layers.Dense(n_units, activation=activation))\n",
    "#model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Second hidden layer:\n",
    "model.add(layers.Dense(n_units, activation=activation))\n",
    "\n",
    "# final layer:  just 1 node and no activation function\n",
    "model.add(layers.Dense(num_classes,activation=None))\n",
    "\n",
    "# normalize output to turn values into \"likilihoods\" that sum to 1.0\n",
    "model.add(layers.Activation('softmax'))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate),  # Adam optimizer\n",
    "            loss='sparse_categorical_crossentropy',       # mean absolute error = mae\n",
    "            metrics=['accuracy'])  # mean squared error = mse\n",
    "\n",
    "# Now train the model\n",
    "# training input: x\n",
    "# training output: y  \n",
    "# Train on batches of 128 samples (chunk size).\n",
    "# Epochs: run through all training data that many times. Order gets shuffled.\n",
    "\n",
    "history = model.fit(x, y_class, epochs=n_epochs, batch_size=batch_size, verbose=0, validation_split=0.2, shuffle=True)   \n",
    "print('done training')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#-----------------------------------------\n",
    "# plot the loss during training\n",
    "#-----------------------------------------\n",
    "#from keras.callbacks import history \n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'],label = 'training')\n",
    "plt.plot(history.history['val_loss'], label = 'testing')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'],label = 'training')\n",
    "plt.plot(history.history['val_accuracy'], label = 'testing')\n",
    "plt.title('accuracy')\n",
    "plt.ylim(0,1)\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1645363448828,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "OZo2PmSOS-lP"
   },
   "outputs": [],
   "source": [
    "# make predictions with your model\n",
    "ypred_class = model.predict(x)         # predict the probability/likelihood of each class with your trained model\n",
    "# ypred = np.argmax(ypred_class,axis=1)  # compute which class has the highest probability/likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1645363449882,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "lLl5KyA1S-lP",
    "outputId": "e2301cda-8080-4ce5-97e8-656ab01741b5"
   },
   "outputs": [],
   "source": [
    "# make predictions with your model\n",
    "ypred_class = model.predict(x)         # predict the probability/likelihood of each class with your trained model\n",
    "ypred = np.argmax(ypred_class,axis=1)  # compute which class has the highest probability/likelihood\n",
    "\n",
    "# create new samples in x\n",
    "px = np.random.random((100 ,1))\n",
    "# predict y\n",
    "py_class = model.predict(px)\n",
    "py = np.argmax(py_class,axis=1)\n",
    "\n",
    "# plot predicted values\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x, y, '.', color='black', label='truth')\n",
    "plt.plot(x, ypred, 'x', color='gray', label='prediction of training data')\n",
    "plt.plot(px, py, '.', color='red', label='prediction of testing data')\n",
    "plt.legend()\n",
    "plt.title('Classification prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nyi5riH7S-lP"
   },
   "source": [
    "#### Let's look at one particular prediction output by the classifier ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645363449882,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "VR8whYKIS-lQ",
    "outputId": "06b55254-48e2-4698-95ff-6a9112035d5b"
   },
   "outputs": [],
   "source": [
    "print('prediction output shape = ' + str(ypred_class.shape))\n",
    "sample = 44\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print('Sample = ' + str(sample) + ', Prediction = ' + str(y_class[sample]))\n",
    "print('Prediction Likelihood [0] = ' + str(ypred_class[sample][0]))\n",
    "print('Prediction Likelihood [1] = ' + str(ypred_class[sample][1]))\n",
    "print('-----------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645363449883,
     "user": {
      "displayName": "Elizabeth Barnes",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiNPVVIWP6XAkP_hwu-8rAxoeeNuk2BMkX5-yuA=s64",
      "userId": "07585723222468022011"
     },
     "user_tz": 420
    },
    "id": "7R7UTTAHS-lQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ann_basics.ipynb",
   "provenance": [
    {
     "file_id": "1NOIH_LI5htjNAbm9UIAteqo3zqQMlfCd",
     "timestamp": 1549487417941
    },
    {
     "file_id": "1SjqkqwQwC-X5FwozGvcPvqPQUppMztEV",
     "timestamp": 1549423168322
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
