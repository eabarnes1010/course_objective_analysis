{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian example with continuous distributions\n",
    "[![Latest release](https://badgen.net/github/release/Naereen/Strapdown.js)](https://github.com/eabarnes1010/course_objective_analysis/tree/main/code)\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eabarnes1010/course_objective_analysis/blob/main/code/bayesian_sst_example.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are interested in measuring the sea-surface temperature (SST) off of the Washington coast to within 0.1 units. You know from previous years that the distribution of anomalous sea-surface temperature (denoted as random variable $X$) follows a uniform distribution with bounds $(-2,2)$. The problem is that the instrument you use to measure the temperature is known to introduce an additive error. While the exact error during each measurement is unknown, you know from calibration that the error follows a normal distribution with $\\mu = 0$ and $\\sigma = 0.75$, denoted at $W$. That is, you measure a random variable $Y$ that is the sum of the two random variables $X$ and $W$: $Y = X + W$.\n",
    "\n",
    "You go out and take a measurement and the instrument says that the anomalous sea-surface temperature is $y = 2.2$. (a) What is the probability that $X = x \\pm \\epsilon$ given that you measured $y$, or in math, $\\textbf{Pr}({X = x \\pm \\epsilon | Y = 2.2 \\pm \\epsilon)}$ for some range determined by $\\epsilon$? (b) For each possible value of $y$, what is your best estimate of $x$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (a): What is the probability that $X = x \\pm \\epsilon$ given that you measured $y$, or in math, $\\textbf{Pr}({X = x \\pm \\epsilon | Y = 2.2 \\pm \\epsilon)}$ for some range determined by $\\epsilon$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_COLAB = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "#.............................................\n",
    "# IMPORT STATEMENTS\n",
    "#.............................................\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import scipy.stats as stats\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print('IN_COLAB = ' + str(IN_COLAB))\n",
    "\n",
    "if IN_COLAB:\n",
    "    %pip install pymc3\n",
    "import pymc3 as pm\n",
    "\n",
    "#.............................................\n",
    "# PLOTTING COMMANDS\n",
    "#.............................................\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "# set figure defaults\n",
    "linewidth_default = 2.0\n",
    "fig_text_default = 18.\n",
    "fig_title_default = fig_text_default*1.5\n",
    "\n",
    "plt.rc('lines', linewidth=linewidth_default)    \n",
    "plt.rc('text', usetex=False)\n",
    "plt.rc('font', size=fig_text_default, weight='normal',family='sans-serif')\n",
    "plt.rc('axes',titlesize=fig_title_default,titleweight='bold')\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "#mpl.rcParams['xtick.labelsize'] = fig_text_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCDF(x,val):\n",
    "    p = len(x[x<=val])/len(x)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get too far into anything, let's start by plotting the distributions that we know. Namely, we know that SSTs, $X$, follows a uniform distribution, and that the error follows a non-standard normal distribution. Let's plot these and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type method which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;31mAttributeError\u001B[0m: 'function' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m     Y \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mDeterministic(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m, W\u001B[38;5;241m+\u001B[39mX)\n\u001B[1;32m      9\u001B[0m x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinspace(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5.\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m---> 10\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(x,\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlogp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# plt.plot(x,np.exp(W.distribution.logp(x).eval()))\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;66;03m# plt.plot(x,np.exp(X.distribution.logp(x).eval()))\u001B[39;00m\n\u001B[1;32m     13\u001B[0m plt\u001B[38;5;241m.\u001B[39mshow()    \n",
      "\u001B[0;31mTypeError\u001B[0m: loop of ufunc does not support argument 0 of type method which has no callable exp method"
     ]
    }
   ],
   "source": [
    "mu_w = 0.\n",
    "var_w = 0.75\n",
    "\n",
    "with pm.Model() as model:\n",
    "    W = pm.Normal('W', mu=mu_w, sigma=var_w)\n",
    "    X = pm.Uniform('X', lower=-2, upper=2)\n",
    "    Y = pm.Deterministic('Y', W+X)\n",
    "\n",
    "x = np.linspace(-5., 5, 1000)\n",
    "plt.plot(x,np.exp(W.distribution.logp(x).eval()))\n",
    "plt.plot(x,np.exp(X.distribution.logp(x).eval()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(1000000, chains=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look like we expect. The question is, what is the distribution of $Y = X + W$? This is actually not so obvious. One way we could figure this out is by actually creating two random variables $X$ and $W$ and adding individual samples together for millions and millions of pairs and then plotting *that* distribution. We could do this, or we could use the nifty pacal package - which is a single line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the distribution of $X, W$ and their sum $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = np.linspace(-5., 5, 100)\n",
    "plt.plot(x,np.exp(W.distribution.logp(x).eval()),label='W')\n",
    "plt.plot(x,np.exp(X.distribution.logp(x).eval()), label='X')\n",
    "sns.distplot(trace['Y'], label='Y=X+W')\n",
    "plt.legend(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvals = trace['Y']\n",
    "xvals = trace['X']\n",
    "wvals = trace['W']\n",
    "print(np.shape(yvals))\n",
    "print(np.shape(xvals))\n",
    "print(np.shape(wvals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the green curve $Y$, perhaps you are not surprised that it lies somewhere \"in the middle\" of the two other distributions. Either way - there it is! Now we can move forward with the problem at hand, now knowing the distrubtion of the sum of the SST measurements ($X$) with the random measurement error ($W$).\n",
    "\n",
    "We can now use Bayes' Theorem to compute what we want to know, namely\n",
    "\\begin{equation}\n",
    "\\textbf{Pr}(X = x \\pm \\epsilon |Y = y = 2.2 \\pm \\epsilon) = \\frac{\\textbf{Pr}(Y = y \\pm \\epsilon | X = x \\pm \\epsilon) \\textbf{Pr}(X = x \\pm \\epsilon)} {\\textbf{Pr}(Y = y \\pm \\epsilon)}\n",
    "\\end{equation}\n",
    "where $\\epsilon$ is determined by you. Here, we will let $\\epsilon = 0.05$.\n",
    "\n",
    "You know that $X$ follows a uniform distribution, and the distribution of $Y$ given $X = x$ follows the normal distribution of $W$ but centered on $\\mu = x$ instead of zero. Determining the distribution of $Y$ is a bit trickier, but we used the pacal module to figure it out. \n",
    "\n",
    "Plugging these distributions into Bayes' Theorem leads to...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = .05\n",
    "yout = 2.2\n",
    "\n",
    "xvec = np.arange(-6.+inc/2.,6.+inc/2.,inc)\n",
    "\n",
    "fx_y_expectation = []\n",
    "fx_y = []       \n",
    "\n",
    "# probability of Y = yout\n",
    "fy = computeCDF(yvals,yout+inc/2.) - computeCDF(yvals,yout-inc/2.)\n",
    "\n",
    "for xout in xvec:\n",
    "\n",
    "    # probability of Y=2.2 given X=x is just the error distribution about x\n",
    "    fy_x = stats.norm.cdf(yout+inc/2.,loc = xout,scale = var_w) - stats.norm.cdf(yout-inc/2.,loc = xout,scale = var_w)\n",
    "\n",
    "    # probability that x = xout\n",
    "    fx = computeCDF(xvals,xout+inc/2.) - computeCDF(xvals,xout-inc/2.)\n",
    "\n",
    "    a = (fy_x * fx/fy)\n",
    "\n",
    "    fx_y.append(a)\n",
    "\n",
    "fx_y = np.array(fx_y)\n",
    "fx_y_expectation = np.sum(xvec * fx_y)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(xvec,fx_y, 'o-', markersize = 4, linewidth = 1)\n",
    "\n",
    "#print np.sum(fx_y)\n",
    "#print np.trapz(fx_y/inc, dx=inc)\n",
    "plt.plot([fx_y_expectation,fx_y_expectation],[0,.14],'--',color = 'gray')\n",
    "\n",
    "plt.xlim(-4.5,4.5)\n",
    "plt.ylim(0,0.075)\n",
    "plt.xlabel('x')\n",
    "plt.title('$\\mathit{f}(X = x \\pm \\epsilon | y = ' + str(yout) + ' \\pm \\epsilon)$')\n",
    "plt.ylabel('probability')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability that $x$ falls within a given interval increases for larger $x$, since we know that $y$ itself is 2.2, and so, to have, say, a negative $x$, we would need to have had a very large error when measuring that sample. The probability goes to zero above 2.0 because we know a priori that $x$ cannot be larger than this. \n",
    "\n",
    "The dashed gray line denotes the conditional expectation of $X$ based on $Y$, that is - the expectation of $X$ given that $y = 2.2 \\pm \\epsilon$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part (b): For each possible value of $y$, what is your best estimate of $x$? \n",
    "\n",
    "To answer this, you must decide what you mean by \"best estimate\". Here, we will define the best estimate based on the posteriori mean. That is, the best estimate of $X$ given $Y = y$ is defined by the *minimum mean squared error estimate*, which is just the expected value of $X$ given $Y = y$. In the case of $Y = y = 2.2$, the best estimate is $x = 1.46$ as shown by the gray dashed line above.\n",
    "\n",
    "For other y-values, we need to iterate through them, perform the same calculation as above, and plot the result as a function of $y_{out}$, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = .05\n",
    "\n",
    "xvec = np.arange(-6.+inc/2.,6.+inc/2.,inc)\n",
    "yout_vec = xvec\n",
    "yout = []\n",
    "\n",
    "fx_y_expectation = []\n",
    "\n",
    "for yout in yout_vec: #loop through many possibilites of y, not just y = 2.2\n",
    "\n",
    "    fx_y = []       \n",
    "    \n",
    "    # probability of Y = yout\n",
    "    fy = computeCDF(yvals,yout+inc/2.) - computeCDF(yvals,yout-inc/2.)\n",
    "    \n",
    "    for xout in xvec:\n",
    "\n",
    "        # probability of Y=2.2 given X=x is just the error distribution about x\n",
    "        fy_x = stats.norm.cdf(yout+inc/2.,loc = xout,scale = var_w) - stats.norm.cdf(yout-inc/2.,loc = xout,scale = var_w)\n",
    "\n",
    "        # probability that x = xout\n",
    "        fx = computeCDF(xvals,xout+inc/2.) - computeCDF(xvals,xout-inc/2.)\n",
    "        a = (fy_x * fx/fy)\n",
    "\n",
    "        fx_y.append(a)\n",
    "\n",
    "    fx_y = np.array(fx_y)\n",
    "    fx_y_expectation.append(np.sum(xvec.astype(float) * fx_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(yout_vec,fx_y_expectation)    \n",
    "plt.xlabel('y')\n",
    "plt.title('E(X|Y=y)')\n",
    "plt.ylabel('x')\n",
    "\n",
    "plt.xlim(-4.5,4.5)\n",
    "plt.ylim(-2.5,2.5)\n",
    "plt.axhline(color='lightgray')\n",
    "\n",
    "plt.plot([-60,60],[-2,-2],'--',linewidth = 1.5, color = 'black')\n",
    "plt.plot([-60,60],[2,2],'--',linewidth = 1.5, color = 'black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing these calculations for all possible values of $y$ leads to the figure above, which shows the most likely sea-surface temperature given that you measure a particular value of $y$. Note how the curve slowly approaches -2 and 2 since $X$ is bounded by these two values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
